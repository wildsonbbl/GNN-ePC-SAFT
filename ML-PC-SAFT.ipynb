{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with GNN-ePC-SAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model combining graph neural network with ePC-SAFT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchmetrics clu ml-collections torch_geometric polars rdkit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.4 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"ray[tune]\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip show jax | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNA EPCSAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x64 on\n",
      "I0725 02:33:31.733999 139696340764480 train.py:255] JAX host: 0 / 1\n",
      "I0725 02:33:31.734216 139696340764480 train.py:256] JAX local devices: [StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n",
      "I0725 02:33:31.734618 139696340764480 train.py:258] Calling train and evaluate\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwildsonbbl\u001b[0m (\u001b[33mwildson\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/notebooks/GNN-ePC-SAFT/wandb/run-20230725_023333-1xz1gdup\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmart-glitter-533\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/wildson/gnn-pc-saft\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/wildson/gnn-pc-saft/runs/1xz1gdup\u001b[0m\n",
      "I0725 02:33:34.318845 139696340764480 train.py:92] Obtaining datasets.\n",
      "inchis saved: 1940\n",
      "I0725 02:33:34.354681 139696340764480 train.py:119] Initializing network.\n",
      "I0725 02:33:36.586852 139696340764480 train.py:171] Starting training.\n",
      "/usr/local/lib/python3.9/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
      "/usr/local/lib/python3.9/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
      "I0725 02:33:37.519251 139696340764480 train.py:193] Finished training step 140001.\n",
      "I0725 02:33:37.604434 139696340764480 train.py:193] Finished training step 140002.\n",
      "I0725 02:33:37.692794 139696340764480 train.py:193] Finished training step 140003.\n",
      "I0725 02:33:37.782079 139696340764480 train.py:193] Finished training step 140004.\n",
      "I0725 02:33:37.858430 139696340764480 train.py:193] Finished training step 140005.\n",
      "I0725 02:33:37.940374 139696340764480 train.py:193] Finished training step 140006.\n",
      "I0725 02:33:38.030121 139696340764480 train.py:193] Finished training step 140007.\n",
      "I0725 02:33:38.108309 139696340764480 train.py:193] Finished training step 140008.\n",
      "I0725 02:33:38.188771 139696340764480 train.py:193] Finished training step 140009.\n",
      "I0725 02:33:38.269165 139696340764480 train.py:193] Finished training step 140010.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/GNN-ePC-SAFT/train.py\", line 265, in <module>\n",
      "    app.run(main)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/notebooks/GNN-ePC-SAFT/train.py\", line 260, in main\n",
      "    train_and_evaluate(FLAGS.config, FLAGS.workdir)\n",
      "  File \"/notebooks/GNN-ePC-SAFT/train.py\", line 178, in train_and_evaluate\n",
      "    for graphs in train_loader:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 681, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 721, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/notebooks/GNN-ePC-SAFT/graphdataset.py\", line 204, in __getitem__\n",
      "    rho = get_padded_array(rho, pad)\n",
      "  File \"/notebooks/GNN-ePC-SAFT/graphdataset.py\", line 227, in get_padded_array\n",
      "    return states[:pad_size, :]\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --workdir=./ --config=configs/default.py \\\n",
    "--config.num_train_steps={int(500000)} --config.log_every_steps=100 --config.num_para=7 \\\n",
    "--config.checkpoint_every_steps=2000 --config.learning_rate=0.0001 --config.patience=1000 \\\n",
    "--config.warmup_steps=100 --config.optimizer={'adam'} --config.batch_size=128 \\\n",
    "--config.propagation_depth=4 --config.hidden_dim=64 --config.num_mlp_layers=2 --config.pre_layers=1 --config.post_layers=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x64 on\n",
      "2023-07-24 23:10:51,762\tERROR utils.py:540 -- Unexpected error calculating docker cpuset ids.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/utils.py\", line 537, in _get_docker_cpus\n",
      "    cpu_ids.append(int(num_or_range))\n",
      "ValueError: invalid literal for int() with base 10: '\\n'\n",
      "2023-07-24 23:10:51,818\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-07-24 23:10:52,882\tINFO experiment_analysis.py:972 -- No trial data passed in during `ExperimentAnalysis` initialization -- you are most likely loading the experiment after it has completed.\n",
      "Loading trial data from the experiment checkpoint file. This may result in loading some stale information, since checkpointing is periodic.\n",
      "2023-07-24 23:10:53,037\tINFO tune.py:666 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-07-24 23:10:53,098\tINFO experiment_state.py:435 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
      "2023-07-24 23:10:53,101\tWARNING trial_runner.py:418 -- Attempting to resume experiment from /notebooks/GNN-ePC-SAFT/ray/tune_with_parameters_2023-07-24_02-37-22. This will ignore any new changes to the specification.\n",
      "2023-07-24 23:10:53,101\tINFO trial_runner.py:422 -- Using the newest experiment state file found within the experiment directory: experiment_state-2023-07-24_20-53-26.json\n",
      "‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n",
      "‚îÇ Configuration for experiment     tune_with_parameters_2023-07-24_02-37-22   ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Search algorithm                 BasicVariantGenerator                      ‚îÇ\n",
      "‚îÇ Scheduler                        AsyncHyperBandScheduler                    ‚îÇ\n",
      "‚îÇ Number of trials                 100                                        ‚îÇ\n",
      "‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n",
      "\n",
      "View detailed results here: /notebooks/GNN-ePC-SAFT/ray/tune_with_parameters_2023-07-24_02-37-22\n",
      "To visualize your results with TensorBoard, run: `tensorboard --logdir /notebooks/GNN-ePC-SAFT/ray/tune_with_parameters_2023-07-24_02-37-22`\n",
      "\n",
      "\n",
      "Best trial config:\n",
      " {'propagation_depth': 4, 'hidden_dim': 64, 'num_mlp_layers': 2, 'pre_layers': 1, 'post_layers': 3}\n",
      "\n",
      "Best trial final metrics:\n",
      " {'train_mape': 0.7611587643623352, 'time_this_iter_s': 4.880785942077637, 'done': True, 'training_iteration': 60, 'trial_id': '04508_00018', 'date': '2023-07-24_04-05-28', 'timestamp': 1690171528, 'time_total_s': 290.06404423713684, 'pid': 6194, 'hostname': 'ntcglqxf14', 'node_ip': '10.38.155.142', 'config': {'propagation_depth': 4, 'hidden_dim': 64, 'num_mlp_layers': 2, 'pre_layers': 1, 'post_layers': 3}, 'time_since_restore': 290.06404423713684, 'iterations_since_restore': 60, 'experiment_tag': '18_hidden_dim=64,num_mlp_layers=2,post_layers=3,pre_layers=1,propagation_depth=4'}\n"
     ]
    }
   ],
   "source": [
    "!python tuner_restore.py --workdir=/notebooks/GNN-ePC-SAFT/ --config=configs/default.py \\\n",
    "--restoredir=./ray/tune_with_parameters_2023-07-24_02-37-22 \\\n",
    "--config.num_train_steps=6000 --config.log_every_steps=100\\\n",
    "--config.learning_rate=0.001 --config.warmup_steps=100 --config.optimizer={'adam'} --config.batch_size=128\\\n",
    "--config.num_para=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py --workdir=./ --config=configs/default.py \\\n",
    "--config.num_train_steps={int(500000)} --config.log_every_steps=100 --config.num_para=7\\\n",
    "--config.checkpoint_every_steps=2000 --config.learning_rate=0.00001 --config.warmup_steps=100 --config.optimizer={'adam'} --config.batch_size=128\\\n",
    "--config.propagation_depth=5 --config.hidden_dim=512 --config.num_mlp_layers=2 --config.pre_layers=2 --config.post_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f019609534c17fc0280e3612935020eee50536f0cea28bd1fe10f7c21931aaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
