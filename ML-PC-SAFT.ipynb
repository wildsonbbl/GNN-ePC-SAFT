{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with GNN-ePC-SAFT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model combining graph neural network with ePC-SAFT\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T18:18:29.541372Z",
     "iopub.status.busy": "2023-06-19T18:18:29.540499Z",
     "iopub.status.idle": "2023-06-19T18:18:30.834792Z",
     "shell.execute_reply": "2023-06-19T18:18:30.833772Z",
     "shell.execute_reply.started": "2023-06-19T18:18:29.541341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T18:18:33.083963Z",
     "iopub.status.busy": "2023-06-19T18:18:33.083292Z",
     "iopub.status.idle": "2023-06-19T18:18:35.081553Z",
     "shell.execute_reply": "2023-06-19T18:18:35.080251Z",
     "shell.execute_reply.started": "2023-06-19T18:18:33.083937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 0.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show jax | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T18:18:41.758672Z",
     "iopub.status.busy": "2023-06-19T18:18:41.758356Z",
     "iopub.status.idle": "2023-06-19T18:19:11.294844Z",
     "shell.execute_reply": "2023-06-19T18:19:11.294073Z",
     "shell.execute_reply.started": "2023-06-19T18:18:41.758647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwildsonbbl\u001b[0m (\u001b[33mwildson\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T18:19:20.237114Z",
     "iopub.status.busy": "2023-06-19T18:19:20.236121Z",
     "iopub.status.idle": "2023-06-19T18:19:20.984437Z",
     "shell.execute_reply": "2023-06-19T18:19:20.983484Z",
     "shell.execute_reply.started": "2023-06-19T18:19:20.237082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  4 00:40:36 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.06              Driver Version: 536.40       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GT 1030         On  | 00000000:01:00.0  On |                  N/A |\n",
      "| 57%   38C    P0              N/A /  30W |    378MiB /  2048MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        22      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNA EPCSAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T21:29:14.573665Z",
     "iopub.status.busy": "2023-06-19T21:29:14.573243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x64 on\n",
      "I0704 00:53:33.436789 140522211104576 main.py:26] JAX host: 0 / 1\n",
      "I0704 00:53:33.437009 140522211104576 main.py:27] JAX local devices: [StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n",
      "I0704 00:53:33.437403 140522211104576 main.py:29] Calling train and evaluate\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwildsonbbl\u001b[0m (\u001b[33mwildson\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/wildsonbbl/documents/code/ePC-SAFT/wandb/run-20230704_005338-rxii8p5a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-eon-392\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/wildson/gnn-pc-saft\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/wildson/gnn-pc-saft/runs/rxii8p5a\u001b[0m\n",
      "I0704 00:53:47.061941 140522211104576 train.py:88] Obtaining datasets.\n",
      "inchis saved: 114\n",
      "I0704 00:53:47.161800 140522211104576 train.py:114] Initializing network.\n",
      "I0704 00:53:52.235731 140522211104576 train.py:157] Starting training.\n",
      "I0704 00:53:54.464482 140522211104576 train.py:180] Finished training step 2001.\n",
      "I0704 00:53:54.618393 140522211104576 train.py:180] Finished training step 2002.\n",
      "I0704 00:53:54.769174 140522211104576 train.py:180] Finished training step 2003.\n",
      "I0704 00:53:54.928829 140522211104576 train.py:180] Finished training step 2004.\n",
      "I0704 00:53:55.070410 140522211104576 train.py:180] Finished training step 2005.\n",
      "I0704 00:53:55.232124 140522211104576 train.py:180] Finished training step 2006.\n",
      "I0704 00:53:55.382042 140522211104576 train.py:180] Finished training step 2007.\n",
      "I0704 00:53:55.538884 140522211104576 train.py:180] Finished training step 2008.\n",
      "I0704 00:53:55.689516 140522211104576 train.py:180] Finished training step 2009.\n",
      "I0704 00:53:55.843731 140522211104576 train.py:180] Finished training step 2010.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_HuberLoss ‚ñá‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_HuberLoss 8.11833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_lr 0.00059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mlively-eon-392\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/wildson/gnn-pc-saft/runs/rxii8p5a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230704_005338-rxii8p5a/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py --workdir=./training --config=configs/default.py \\\n",
    "--config.num_train_steps={int(4000)} --config.log_every_steps=14 --config.pad_size=64\\\n",
    "--config.checkpoint_every_steps=2000 --config.learning_rate=0.001 --config.warmup_steps=14 --config.optimizer={'adam'} --config.batch_size=128\\\n",
    "--config.propagation_depth={int(3)} --config.hidden_dim={int(64)} --config.num_mlp_layers={int(1)} --config.num_para={int(3)} --config.pre_layers=1 --config.post_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f019609534c17fc0280e3612935020eee50536f0cea28bd1fe10f7c21931aaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
