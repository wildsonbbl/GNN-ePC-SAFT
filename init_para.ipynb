{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ff522-3521-4d89-b90e-042aa95fcc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "import torch, numpy as np, polars as pl\n",
    "from data.graphdataset import ThermoMLDataset, ramirez\n",
    "from train.train import create_model\n",
    "from train.model_deg import calc_deg\n",
    "from train.parametrisation import MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3158ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_loader = ramirez(\"./data/ramirez2022\")\n",
    "ra_para = {}\n",
    "for graph in ra_loader:\n",
    "    inchi, para = graph.InChI, graph.para.view(-1, 3).round(decimals=2)\n",
    "    ra_para[inchi] = para.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77810b2-ca9c-4212-8b4d-5ff00bee47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join(\"data\", \"thermoml\")\n",
    "testloader = ThermoMLDataset(path)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e983bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.default import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee710698",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.propagation_depth=4\n",
    "config.hidden_dim=128\n",
    "config.num_mlp_layers=2\n",
    "config.pre_layers=1\n",
    "config.post_layers=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the network.\n",
    "deg = calc_deg(\"ramirez\", './')\n",
    "model = create_model(config, deg).to(device, model_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42712c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpointing of the model.\n",
    "ckp_path = \"./train/checkpoints/model3-4_35e6.pth\"\n",
    "if osp.exists(ckp_path):\n",
    "    checkpoint = torch.load(ckp_path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"model checkpoint step {checkpoint['step']}\")\n",
    "    del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc00a5e-1816-4bbf-9a89-e677905831d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_para = {}\n",
    "model_array = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for graphs in testloader:\n",
    "        graphs.x = graphs.x.to(model_dtype)\n",
    "        graphs.edge_attr = graphs.edge_attr.to(model_dtype)\n",
    "        graphs.edge_index = graphs.edge_index.to(torch.int64)\n",
    "\n",
    "        graphs = graphs.to(device)\n",
    "        parameters = model(graphs)\n",
    "        params = parameters.squeeze().to(torch.float64).numpy()\n",
    "        rho = graphs.rho.view(-1, 5).to(torch.float64).numpy()\n",
    "        vp = graphs.vp.view(-1, 5).to(torch.float64).numpy()\n",
    "        n_datapoints = rho.shape[0] + vp.shape[0]\n",
    "        if n_datapoints < 10:\n",
    "            continue\n",
    "        mden_array, mvp_array = MAPE(params, rho, vp, False)\n",
    "        if (mvp_array.size == 0):\n",
    "            continue\n",
    "        mden, mvp = mden_array.mean(), mvp_array.mean()\n",
    "        parameters = parameters.tolist()[0]\n",
    "        model_para[graphs.InChI] = (parameters, mden, mvp)\n",
    "        model_array[graphs.InChI] = (mden_array, mvp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "para3 = {}\n",
    "for inchi in model_para:\n",
    "    if inchi not in ra_para:\n",
    "        para3[inchi] = model_para[inchi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ra_para), len(model_para), len(para3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a94666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/thermoml/processed/para3.pkl\", \"wb\") as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(para3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872033a-f50f-4340-8d47-9b89388fc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/thermoml/raw/para3_fitted.pkl\", \"wb\") as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(para3, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
