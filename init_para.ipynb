{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71ff522-3521-4d89-b90e-042aa95fcc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "import torch, numpy as np\n",
    "from data.graphdataset import ThermoMLDataset, ramirez, ThermoMLpara\n",
    "from train.train import create_model\n",
    "from train.model_deg import calc_deg\n",
    "from data.graph import from_InChI\n",
    "from train.parametrisation import MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3158ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ef1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ramirez(\"./data/ramirez2022\")\n",
    "ra_para = {}\n",
    "for graph in train_loader:\n",
    "    inchi, para = graph.InChI, graph.para.view(-1, 3)\n",
    "    ra_para[inchi] = para.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e13809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ThermoMLpara(\"./data/thermoml\")\n",
    "tml_para = {}\n",
    "for graph in train_loader:\n",
    "    inchi, para = graph.InChI, graph.para.view(-1, 3)\n",
    "    tml_para[inchi] = para.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77810b2-ca9c-4212-8b4d-5ff00bee47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = osp.join(\"data\", \"thermoml\")\n",
    "testloader = ThermoMLDataset(path)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e983bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.default import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee710698",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.propagation_depth=4\n",
    "config.hidden_dim=128\n",
    "config.num_mlp_layers=2\n",
    "config.pre_layers=1\n",
    "config.post_layers=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b7cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the network.\n",
    "deg = calc_deg(\"thermoml\", './')\n",
    "model = create_model(config, deg).to(device, model_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42712c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model checkpoint step 240000\n"
     ]
    }
   ],
   "source": [
    "# Set up checkpointing of the model.\n",
    "ckp_path = \"./train/checkpoints/model5-240k.pth\"\n",
    "if osp.exists(ckp_path):\n",
    "    checkpoint = torch.load(ckp_path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"model checkpoint step {checkpoint['step']}\")\n",
    "    del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc00a5e-1816-4bbf-9a89-e677905831d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_para = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for graphs in testloader:\n",
    "        graphs.x = graphs.x.to(torch.float64)\n",
    "        graphs.edge_attr = graphs.edge_attr.to(torch.float64)\n",
    "        graphs.edge_index = graphs.edge_index.to(torch.int64)\n",
    "\n",
    "        graphs = graphs.to(device)\n",
    "        parameters = model(graphs)\n",
    "        params = parameters.squeeze().to(torch.float64).detach().numpy()\n",
    "        rho = graphs.rho.view(-1, 5).to(torch.float64).numpy()\n",
    "        vp = graphs.vp.view(-1, 5).to(torch.float64).numpy()\n",
    "        mden, mvp = MAPE(params, rho, vp)\n",
    "        parameters = parameters.tolist()[0]\n",
    "        model_para[graphs.InChI] = (parameters, mden, mvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"inchis\":[],\"mden\":[],\"mvp\":[]}\n",
    "for inchi in ra_para:\n",
    "    if inchi in model_para:\n",
    "        ml, mden, mvp = model_para[inchi]\n",
    "        ra = np.array(ra_para[inchi])\n",
    "        ml = np.array(ml)\n",
    "        mape = np.abs(ra - ml) / ra * 100\n",
    "        data[\"inchis\"].append(inchi)\n",
    "        data[\"mden\"].append(mden)\n",
    "        data[\"mvp\"].append(mvp)\n",
    "        \n",
    "        if (mden > 100 / 100 or mvp > 100 / 100):\n",
    "            print(inchi)\n",
    "            print(f\"###########---{mape}---##########\")\n",
    "            print(f\"###########---{mden*100, mvp*100}---##########\")\n",
    "            for row in zip(ra, ml):\n",
    "                print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385bdb98-fa88-49c3-bf95-0cc5c2cdacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "data = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304606d-6eb3-4a0a-ba0f-11dfca0c1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write_csv(\"modelx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a94666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/thermoml/processed/para3.pkl\", \"wb\") as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(model_para, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872033a-f50f-4340-8d47-9b89388fc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/thermoml/raw/para3_fitted.pkl\", \"wb\") as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(model_para, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3af3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rho_vp = 0\n",
    "n_rho = 0\n",
    "n_vp = 0\n",
    "ntrain = 0\n",
    "ntrain_rhovp = 0\n",
    "size_vp = 0\n",
    "size_rho = 0\n",
    "for graph in testloader:\n",
    "    if torch.all(graph.rho == torch.zeros_like(graph.rho)):\n",
    "        n_vp += 1\n",
    "    elif torch.all(graph.vp == torch.zeros_like(graph.vp)):\n",
    "        n_rho += 1\n",
    "    else:\n",
    "        n_rho_vp += 1\n",
    "        if graph.InChI not in ra_para:\n",
    "            ntrain_rhovp += 1 \n",
    "    \n",
    "    if graph.InChI not in ra_para:\n",
    "        ntrain += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rho_vp, n_rho, n_vp, ntrain, ntrain_rhovp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91369b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, numpy as np\n",
    "with open(\"./data/thermoml/raw/para3_fitted.pkl\", \"rb\") as file:\n",
    "        # A new file will be created\n",
    "        para_fitted = pickle.load( file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e74a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "nra = 0\n",
    "for inchi in para_fitted:\n",
    "    ml, mden, mvp = para_fitted[inchi]\n",
    "    if ( (mden > 0.05) or (mvp > 0.05) ):\n",
    "            print(inchi)\n",
    "            print(f\"###########---{mden, mvp}---##########\")\n",
    "            print(ml)\n",
    "            n +=1\n",
    "    if inchi in ra_para:\n",
    "        nra += 1\n",
    "print(f\"number of test set left: {n}\")\n",
    "print(f\"number of train set: {len(para_fitted) - n}\")\n",
    "print(f\"number of val set: {nra}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
