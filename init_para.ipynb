{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ff522-3521-4d89-b90e-042aa95fcc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "import torch, numpy as np, polars as pl\n",
    "from data.graphdataset import ThermoMLDataset, ramirez, ThermoMLpara\n",
    "from train.train import create_model\n",
    "from train.model_deg import calc_deg\n",
    "from data.graph import from_InChI\n",
    "from train.parametrisation import MAPE, APE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3158ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_loader = ramirez(\"./data/ramirez2022\")\n",
    "ra_para = {}\n",
    "for graph in ra_loader:\n",
    "    inchi, para = graph.InChI, graph.para.view(-1, 3).round(decimals=2)\n",
    "    ra_para[inchi] = para.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e13809",
   "metadata": {},
   "outputs": [],
   "source": [
    "tml_loader = ThermoMLpara(\"./data/thermoml\")\n",
    "tml_para = {}\n",
    "for graph in tml_loader:\n",
    "    inchi, para = graph.InChI, graph.para.view(-1, 3).round(decimals=2)\n",
    "    tml_para[inchi] = para.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77810b2-ca9c-4212-8b4d-5ff00bee47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join(\"data\", \"thermoml\")\n",
    "testloader = ThermoMLDataset(path)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e983bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.default import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee710698",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.propagation_depth=4\n",
    "config.hidden_dim=128\n",
    "config.num_mlp_layers=2\n",
    "config.pre_layers=1\n",
    "config.post_layers=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the network.\n",
    "deg = calc_deg(\"thermoml\", './')\n",
    "model = create_model(config, deg).to(device, model_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42712c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpointing of the model.\n",
    "ckp_path = \"./train/checkpoints/model2-2_67e6.pth\"\n",
    "if osp.exists(ckp_path):\n",
    "    checkpoint = torch.load(ckp_path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"model checkpoint step {checkpoint['step']}\")\n",
    "    del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc00a5e-1816-4bbf-9a89-e677905831d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_para = {}\n",
    "model_array = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for graphs in testloader:\n",
    "        graphs.x = graphs.x.to(model_dtype)\n",
    "        graphs.edge_attr = graphs.edge_attr.to(model_dtype)\n",
    "        graphs.edge_index = graphs.edge_index.to(torch.int64)\n",
    "\n",
    "        graphs = graphs.to(device)\n",
    "        parameters = model(graphs)\n",
    "        params = parameters.squeeze().to(torch.float64).detach().numpy()\n",
    "        rho = graphs.rho.view(-1, 5).to(torch.float64).numpy()\n",
    "        vp = graphs.vp.view(-1, 5).to(torch.float64).numpy()\n",
    "        mden, mvp = MAPE(params, rho, vp)\n",
    "        mden_array, mvp_array = APE(params, rho, vp)\n",
    "        parameters = parameters.tolist()[0]\n",
    "        model_para[graphs.InChI] = (parameters, mden, mvp)\n",
    "        model_array[graphs.InChI] = (mden_array, mvp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inchi in ra_para:\n",
    "    if inchi in model_para:\n",
    "        ml, mden, mvp = model_para[inchi]\n",
    "        ra = np.array(ra_para[inchi])\n",
    "        ml = np.array(ml)\n",
    "        mape = np.abs(ra - ml) / ra * 100\n",
    "        \n",
    "        if (mden > 50 / 100 or mvp > 50 / 100):\n",
    "            print(inchi)\n",
    "            print(f\"###########---{mape}---##########\")\n",
    "            print(f\"###########---{mden*100, mvp*100}---##########\")\n",
    "            for row in zip(ra, ml):\n",
    "                print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501020ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"inchis\":[],\"mden\":[],\"mvp\":[]}\n",
    "for inchi in model_para:\n",
    "    data['inchis'].append(inchi)\n",
    "    data['mden'].append(model_para[inchi][1])\n",
    "    data['mvp'].append(model_para[inchi][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12995f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8170fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx.write_csv('model2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a94666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/thermoml/processed/para3.pkl\", \"wb\") as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(model_para, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872033a-f50f-4340-8d47-9b89388fc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/thermoml/raw/para3_fitted.pkl\", \"wb\") as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(model_para, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3af3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rho_vp = 0\n",
    "n_rho = 0\n",
    "n_vp = 0\n",
    "ntrain = 0\n",
    "ntrain_rhovp = 0\n",
    "size_vp = 0\n",
    "size_rho = 0\n",
    "for graph in testloader:\n",
    "    if torch.all(graph.rho == torch.zeros_like(graph.rho)):\n",
    "        n_vp += 1\n",
    "    elif torch.all(graph.vp == torch.zeros_like(graph.vp)):\n",
    "        n_rho += 1\n",
    "    else:\n",
    "        n_rho_vp += 1\n",
    "        if graph.InChI not in ra_para:\n",
    "            ntrain_rhovp += 1 \n",
    "    \n",
    "    if graph.InChI not in ra_para:\n",
    "        ntrain += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rho_vp, n_rho, n_vp, ntrain, ntrain_rhovp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91369b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, numpy as np\n",
    "with open(\"./data/thermoml/raw/para3_fitted.pkl\", \"rb\") as file:\n",
    "        # A new file will be created\n",
    "        para_fitted = pickle.load( file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e74a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "nra = 0\n",
    "for inchi in para_fitted:\n",
    "    ml, mden, mvp = para_fitted[inchi]\n",
    "    if ( (mden > 0.05) or (mvp > 0.05) ):\n",
    "            print(inchi)\n",
    "            print(f\"###########---{mden, mvp}---##########\")\n",
    "            print(ml)\n",
    "            n +=1\n",
    "    if inchi in ra_para:\n",
    "        nra += 1\n",
    "print(f\"number of test set left: {n}\")\n",
    "print(f\"number of train set: {len(para_fitted) - n}\")\n",
    "print(f\"number of val set: {nra}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38e07139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.2799999713897705, 1.8596061168889244, 2.6351581871134684)\n",
      "(1.9600000381469727, 2.18422885014196, 2.1185829815421897)\n",
      "(298.20001220703125, 341.5310241437917, 337.4404198471014)\n",
      "0.2468140099559228 1000000.0 0.008767997939916464 0.007596301684148007\n"
     ]
    }
   ],
   "source": [
    "inchi = \"InChI=1S/H2O/h1H2\"\n",
    "ml, mden, mvp = model_para[inchi]\n",
    "mden_array, mvp_array = model_array[inchi]\n",
    "ra = ra_para[inchi]\n",
    "fit, mden_fit, mvp_fit = para_fitted[inchi]\n",
    "for row in zip(ra, ml, fit):\n",
    "    print(row)\n",
    "\n",
    "print(mden, mvp, mden_fit, mvp_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c87ef2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.8596,   2.1842, 341.5310]], dtype=torch.float64),\n",
       " array([  1.859,   2.184, 341.5  ], dtype=float16))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    graphs = from_InChI(inchi, with_hydrogen=True)\n",
    "    graphs.x = graphs.x.to(model_dtype)\n",
    "    graphs.edge_attr = graphs.edge_attr.to(model_dtype)\n",
    "    graphs.edge_index = graphs.edge_index.to(torch.int64)\n",
    "\n",
    "    graphs = graphs.to(device)\n",
    "    parameters = model(graphs)\n",
    "    params = parameters.squeeze().to(torch.float16).detach().numpy()\n",
    "parameters, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7293204c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], InChI='InChI=1S/H2O/h1H2', vp=[553, 5], rho=[1651, 5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for gh in testloader:\n",
    "    if gh.InChI == inchi:\n",
    "        break\n",
    "gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03bcdc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.2315e+02, 1.2235e+04, 1.0000e+00, 3.0000e+00, 1.2235e+04],\n",
       "         [3.3315e+02, 1.9821e+04, 1.0000e+00, 3.0000e+00, 1.9821e+04],\n",
       "         [3.4315e+02, 3.0815e+04, 1.0000e+00, 3.0000e+00, 3.0815e+04],\n",
       "         ...,\n",
       "         [3.7281e+02, 1.0000e+05, 1.0000e+00, 3.0000e+00, 1.0000e+05],\n",
       "         [3.7284e+02, 1.0000e+05, 1.0000e+00, 3.0000e+00, 1.0000e+05],\n",
       "         [3.7290e+02, 1.0100e+05, 1.0000e+00, 3.0000e+00, 1.0100e+05]],\n",
       "        dtype=torch.float64),\n",
       " array([1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000., 1000000., 1000000., 1000000., 1000000., 1000000.,\n",
       "        1000000.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh.vp, mvp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6bea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
